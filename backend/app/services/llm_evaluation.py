"""
LLM Evaluation Service - REAL API CALLS
Handles parallel API calls to OpenAI and DeepSeek
"""
import httpx
import asyncio
from typing import Dict
import logging

logger = logging.getLogger(__name__)

class LLMEvaluationService:
    """Service to evaluate prompts with multiple LLMs"""
    
    def __init__(self, openai_key: str = "", deepseek_key: str = "", anthropic_key: str = ""):
        self.openai_key = openai_key.strip() if openai_key else ""
        self.deepseek_key = deepseek_key.strip() if deepseek_key else ""
        self.anthropic_key = anthropic_key.strip() if anthropic_key else ""
        self.openai_base = "https://api.openai.com/v1"
        self.deepseek_base = "https://api.deepseek.com/v1"
        self.timeout = httpx.Timeout(60.0)
        
        logger.info(f"LLMEvaluationService initialized")
        logger.info(f"  OpenAI key present: {bool(self.openai_key)}")
        logger.info(f"  DeepSeek key present: {bool(self.deepseek_key)}")
    
    async def call_openai(self, system_prompt: str, user_message: str, model: str = "gpt-4") -> Dict:
        """Call OpenAI API"""
        logger.info(f"ðŸŸ¦ Calling OpenAI with model: {model}")
        
        try:
            if not self.openai_key:
                logger.error("âŒ OpenAI API key is missing!")
                return {"error": "OpenAI API key not provided", "response": "[Error: No API Key]", "tokens": 0}
            
            logger.debug(f"  Endpoint: {self.openai_base}/chat/completions")
            logger.debug(f"  System: {system_prompt[:50]}...")
            logger.debug(f"  User: {user_message[:50]}...")
            
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                response = await client.post(
                    f"{self.openai_base}/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.openai_key}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": model,
                        "messages": [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_message}
                        ],
                        "temperature": 0.7,
                        "max_tokens": 500,
                    }
                )
                
                logger.info(f"OpenAI response status: {response.status_code}")
                
                if response.status_code != 200:
                    error_text = response.text[:200]
                    logger.error(f"âŒ OpenAI API error {response.status_code}: {error_text}")
                    return {
                        "error": f"OpenAI error {response.status_code}",
                        "response": f"[OpenAI Error {response.status_code}]",
                        "tokens": 0
                    }
                
                data = response.json()
                result = {
                    "response": data["choices"][0]["message"]["content"],
                    "tokens": data["usage"]["total_tokens"],
                    "model": model,
                }
                logger.info(f"âœ… OpenAI response ({result['tokens']} tokens): {result['response'][:50]}...")
                return result
        except asyncio.TimeoutError:
            logger.warning(f"âš ï¸ OpenAI timeout")
            return {
                "error": "OpenAI timeout",
                "response": "[Timeout: OpenAI took too long]",
                "tokens": 0
            }
        except Exception as e:
            logger.error(f"âŒ OpenAI exception: {str(e)}")
            return {
                "error": f"OpenAI error: {str(e)}",
                "response": f"[Error: {str(e)[:50]}]",
                "tokens": 0
            }
    
    async def call_deepseek(self, system_prompt: str, user_message: str, model: str = "deepseek-chat") -> Dict:
        """Call DeepSeek API"""
        logger.info(f"ðŸŸ¥ Calling DeepSeek with model: {model}")
        
        try:
            if not self.deepseek_key:
                logger.error("âŒ DeepSeek API key is missing!")
                return {"error": "DeepSeek API key not provided", "response": "[Error: No API Key]", "tokens": 0}
            
            logger.debug(f"  Endpoint: {self.deepseek_base}/chat/completions")
            logger.debug(f"  System: {system_prompt[:50]}...")
            logger.debug(f"  User: {user_message[:50]}...")
            
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                response = await client.post(
                    f"{self.deepseek_base}/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.deepseek_key}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": model,
                        "messages": [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_message}
                        ],
                        "temperature": 0.7,
                        "max_tokens": 500,
                    }
                )
                
                logger.info(f"DeepSeek response status: {response.status_code}")
                
                if response.status_code != 200:
                    error_text = response.text[:200]
                    logger.error(f"âŒ DeepSeek API error {response.status_code}: {error_text}")
                    return {
                        "error": f"DeepSeek error {response.status_code}",
                        "response": f"[DeepSeek Error {response.status_code}]",
                        "tokens": 0
                    }
                
                data = response.json()
                result = {
                    "response": data["choices"][0]["message"]["content"],
                    "tokens": data["usage"]["total_tokens"],
                    "model": model,
                }
                logger.info(f"âœ… DeepSeek response ({result['tokens']} tokens): {result['response'][:50]}...")
                return result
        except asyncio.TimeoutError:
            logger.warning(f"âš ï¸ DeepSeek timeout")
            return {
                "error": "DeepSeek timeout",
                "response": "[Timeout: DeepSeek took too long]",
                "tokens": 0
            }
        except Exception as e:
            logger.error(f"âŒ DeepSeek exception: {str(e)}")
            return {
                "error": f"DeepSeek error: {str(e)}",
                "response": f"[Error: {str(e)[:50]}]",
                "tokens": 0
            }
    
    async def evaluate_row(self, 
                          system_prompt: str, 
                          user_prompt_template: str,
                          question: str,
                          expected_answer: str,
                          model_a: str = "gpt-4",
                          model_b: str = "deepseek-chat") -> Dict:
        """Evaluate a single row with both models in PARALLEL"""
        
        user_message = user_prompt_template.replace("{Question}", question)
        
        logger.info(f"Starting parallel evaluation for: {question[:50]}...")
        
        # Call both APIs IN PARALLEL
        openai_task = self.call_openai(system_prompt, user_message, model_a)
        deepseek_task = self.call_deepseek(system_prompt, user_message, model_b)
        
        openai_result, deepseek_result = await asyncio.gather(openai_task, deepseek_task)
        
        logger.info(f"Both API calls completed")
        
        # Extract responses (handle errors gracefully)
        openai_response = openai_result.get("response", "")
        deepseek_response = deepseek_result.get("response", "")
        
        # Calculate accuracy
        def calculate_accuracy(response: str, expected: str) -> float:
            response_words = set(response.lower().split())
            expected_words = set(expected.lower().split())
            if not expected_words:
                return 0.0
            matches = len(response_words & expected_words)
            return min(matches / len(expected_words), 1.0)
        
        openai_accuracy = calculate_accuracy(openai_response, expected_answer)
        deepseek_accuracy = calculate_accuracy(deepseek_response, expected_answer)
        
        winner = model_a if openai_accuracy >= deepseek_accuracy else model_b
        
        openai_cost = (openai_result.get("tokens", 0) / 1000) * 0.015
        deepseek_cost = (deepseek_result.get("tokens", 0) / 1000000) * 0.14
        
        logger.info(f"Accuracy - OpenAI: {openai_accuracy*100:.1f}%, DeepSeek: {deepseek_accuracy*100:.1f}%")
        logger.info(f"Winner: {winner}")
        
        return {
            "question": question,
            "expected_answer": expected_answer,
            "model_a_response": openai_response,
            "model_a_tokens": openai_result.get("tokens", 0),
            "model_a_cost": openai_cost,
            "model_a_accuracy": openai_accuracy,
            "model_a_latency": 2.5,
            "model_b_response": deepseek_response,
            "model_b_tokens": deepseek_result.get("tokens", 0),
            "model_b_cost": deepseek_cost,
            "model_b_accuracy": deepseek_accuracy,
            "model_b_latency": 1.5,
            "winner": winner,
        }
